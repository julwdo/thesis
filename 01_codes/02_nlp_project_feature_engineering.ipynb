{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fV-2Mc6kjhr3GdesgLaaXJLp6qV5bBC9",
      "authorship_tag": "ABX9TyNyuGDCJV7YqXWUnDKfu3EN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julwdo/thesis/blob/main/01_codes/02_nlp_project_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null # OpenJDK 17\n",
        "!wget --show-progress https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz # Apache Spark 3.5.6 with Hadoop 3 support\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -q --upgrade pyspark==3.5.6"
      ],
      "metadata": {
        "id": "mQ8T-LAUzBeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd59468-ece8-4653-d1df-5864b20f7d10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-30 14:28:04--  https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400923510 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.6-bin-hadoop3.tgz.2’\n",
            "\n",
            "spark-3.5.6-bin-had 100%[===================>] 382.35M  14.1MB/s    in 26s     \n",
            "\n",
            "2025-12-30 14:28:31 (14.6 MB/s) - ‘spark-3.5.6-bin-hadoop3.tgz.2’ saved [400923510/400923510]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.5.6-bin-hadoop3'"
      ],
      "metadata": {
        "id": "WHawKcY3TCNK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"BotDetection\")\n",
        "    .master(\"local[*]\")\n",
        "    .getOrCreate()\n",
        "    )\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "hBPmK_AXjToH",
        "outputId": "59e3adcd-3f0e-4188-a353-3a0034277752"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a6688c13080>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://01fc5b4615cd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BotDetection</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import math\n",
        "from collections import Counter\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.types import StringType, NumericType, BooleanType, ArrayType, FloatType"
      ],
      "metadata": {
        "id": "J-C_Oc4BzG2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "1dvQfYXH_WoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2b7f4e-0d6b-41e6-ee6b-3dfd0b7065c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "nXzBU7MKS-dT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "in_dir = \"/content/drive/MyDrive/twibot-22/raw\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j6dkdVX825n",
        "outputId": "70ec71c8-4e28-450f-d5eb-67283fa37ca8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = spark.read.json(os.path.join(in_dir, \"user.jsonl\"))\n",
        "#users.printSchema()"
      ],
      "metadata": {
        "id": "4ljK4HtA_MmV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "zfqG1CcW_Q1c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_selected = users.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"name\"),\n",
        "    F.col(\"username\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.col(\"description\"),\n",
        "    F.col(\"url\"),\n",
        "    F.col(\"entities.description.cashtags\"),\n",
        "    F.col(\"entities.description.hashtags\"),\n",
        "    F.col(\"entities.description.mentions\"),\n",
        "    F.col(\"entities.description.urls\"),\n",
        "    F.col(\"location\"),\n",
        "    F.col(\"pinned_tweet_id\"),\n",
        "    F.col(\"profile_image_url\"),\n",
        "    F.col(\"protected\"),\n",
        "    F.col(\"public_metrics.followers_count\"),\n",
        "    F.col(\"public_metrics.following_count\"),\n",
        "    F.col(\"public_metrics.listed_count\"),\n",
        "    F.col(\"public_metrics.tweet_count\"),\n",
        "    F.col(\"verified\")\n",
        "    )"
      ],
      "metadata": {
        "id": "GQAYasduAYqH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ce5ND56SEn8R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "m1nb1FybEtUp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = spark.read.csv(os.path.join(in_dir, \"label.csv\"), header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sDJSz4DuE6_2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "2S3i6OraGnzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cbd617-d6b8-411a-fda0-63cfc12f62cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|id                  |label|\n",
            "+--------------------+-----+\n",
            "|u1217628182611927040|human|\n",
            "|u2664730894         |human|\n",
            "|u1266703520205549568|human|\n",
            "|u1089159225148882949|human|\n",
            "|u36741729           |bot  |\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_labeled = users_selected.join(labels, users_selected.id == labels.id, \"left\").drop(labels.id)"
      ],
      "metadata": {
        "id": "Dx7pGZ1rGpSJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_labeled.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "yxJV0qKaG_Et"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#users_labeled.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in users_labeled.columns]).show()"
      ],
      "metadata": {
        "id": "e29uv2D-P3Zz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(text):\n",
        "  return sia.polarity_scores(text)[\"compound\"]\n",
        "\n",
        "vader_udf = F.udf(vader_sentiment, FloatType())"
      ],
      "metadata": {
        "id": "hR9nb9Q6P7CJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shannon_entropy(string):\n",
        "    if string.strip() == \"\":\n",
        "        return 0.0\n",
        "    counts = Counter(string)\n",
        "    length = len(string)\n",
        "    return -sum((count/length) * math.log2(count/length) for count in counts.values())\n",
        "\n",
        "entropy_udf = F.udf(shannon_entropy, FloatType())"
      ],
      "metadata": {
        "id": "T9Gc6ww0beC5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = F.current_timestamp()"
      ],
      "metadata": {
        "id": "3JkuBNxKOLqc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features_0 = users_labeled.select(\n",
        "    F.col(\"id\"),\n",
        "    F.length(F.col(\"name\")).alias(\"name_length\"),\n",
        "    F.length(F.col(\"username\")).alias(\"username_length\"),\n",
        "    (F.length(F.col(\"username\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_length_ratio\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"description\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"description\"),\n",
        "    F.length(F.col(\"description\")).alias(\"description_length\"),\n",
        "    F.when(F.col(\"name\") == \"\", False).otherwise(True).alias(\"has_name\"),\n",
        "    F.when(F.col(\"username\") == \"\", False).otherwise(True).alias(\"has_username\"),\n",
        "    F.when(F.col(\"description\") == \"\", False).otherwise(True).alias(\"has_description\"),\n",
        "    F.when(F.col(\"url\") == \"\", False).otherwise(True).alias(\"has_url\"),\n",
        "    F.when(F.col(\"location\").isNull() | (F.col(\"location\") == \"\"), False).otherwise(True).alias(\"has_location\"),\n",
        "    F.when(F.col(\"pinned_tweet_id\").isNull(), False).otherwise(True).alias(\"has_pinned_tweet\"),\n",
        "    F.col(\"name\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_name\"),\n",
        "    F.col(\"description\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_digits_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_digits_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_digits_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_special_chars_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_special_chars_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_special_chars_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"name\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"name_upper_to_lower_ratio\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"username\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"username_upper_to_lower_ratio\"),\n",
        "    entropy_udf(F.col(\"name\")).alias(\"name_entropy\"),\n",
        "    entropy_udf(F.col(\"username\")).alias(\"username_entropy\"),\n",
        "    (F.levenshtein(F.col(\"username\"), F.col(\"name\")) / F.greatest(F.length(F.col(\"username\")), F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_levenshtein\"),\n",
        "    vader_udf(F.col(\"description\")).alias(\"description_sentiment\"),\n",
        "    F.when(F.col(\"cashtags\").isNotNull(), F.size(F.col(\"cashtags\"))).otherwise(F.lit(0)).alias(\"cashtag_in_description_count\"),\n",
        "    F.when(F.col(\"hashtags\").isNotNull(), F.size(F.col(\"hashtags\"))).otherwise(F.lit(0)).alias(\"hashtag_in_description_count\"),\n",
        "    F.when(F.col(\"mentions\").isNotNull(), F.size(F.col(\"mentions\"))).otherwise(F.lit(0)).alias(\"mention_in_description_count\"),\n",
        "    F.when(F.col(\"urls\").isNotNull(), F.size(F.col(\"urls\"))).otherwise(F.lit(0)).alias(\"url_in_description_count\"),\n",
        "    F.col(\"protected\").alias(\"is_protected\"),\n",
        "    F.col(\"verified\").alias(\"is_verified\"),\n",
        "    (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\"))).alias(\"account_age_seconds\"),\n",
        "    F.col(\"followers_count\"),\n",
        "    F.col(\"following_count\"),\n",
        "    F.col(\"listed_count\"),\n",
        "    F.col(\"tweet_count\"),\n",
        "    (F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"followers_over_following\"),\n",
        "    (2 * F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"double_followers_over_following\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"following_over_followers\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") ** 2, F.lit(1))).alias(\"following_over_followers_squared\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") + F.col(\"following_count\"), F.lit(1))).alias(\"following_over_total_connections\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"listed_over_followers\"),\n",
        "    (F.col(\"tweet_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"tweets_over_followers\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"tweet_count\"), F.lit(1))).alias(\"listed_over_tweets\"),\n",
        "    (F.col(\"followers_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"follower_rate\"),\n",
        "    (F.col(\"following_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"following_rate\"),\n",
        "    (F.col(\"listed_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"listed_rate\"),\n",
        "    (F.col(\"tweet_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"tweet_rate\"),\n",
        "    F.col(\"label\")\n",
        "    )"
      ],
      "metadata": {
        "id": "S2TklOE1NR4W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = spark.read.json(os.path.join(in_dir, \"tweet_0.jsonl\"))\n",
        "#tweets.printSchema()"
      ],
      "metadata": {
        "id": "BoXGa7V54LOz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "WQcJouz95AqR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_selected = tweets.select(\n",
        "    F.col(\"id\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"text\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"text\"),\n",
        "    F.concat(F.lit(\"u\"), F.col(\"author_id\")).alias(\"author_id\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.when(F.col(\"in_reply_to_user_id\").isNull(), False).otherwise(True).cast(\"int\").alias(\"is_reply\"),\n",
        "    F.col(\"lang\"),\n",
        "    F.col(\"possibly_sensitive\").cast(\"int\").alias(\"is_sensitive\"),\n",
        "    F.col(\"public_metrics.like_count\"),\n",
        "    F.col(\"public_metrics.quote_count\"),\n",
        "    F.col(\"public_metrics.reply_count\"),\n",
        "    F.col(\"public_metrics.retweet_count\")\n",
        "    )"
      ],
      "metadata": {
        "id": "YUIgowMCnixE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ksw3FbI0oI30"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Olt6LrVdNQEB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#tweets_selected.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tweets_selected.columns]).show()"
      ],
      "metadata": {
        "id": "nwL2Tp8gNydF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for English-language tweets\n",
        "tweets_en = tweets_selected.filter(F.col(\"lang\") == \"en\").drop(\"lang\")"
      ],
      "metadata": {
        "id": "adVUQsEfktUy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter top 20 tweets per author\n",
        "window = Window.partitionBy(\"author_id\").orderBy(F.col(\"created_at\").desc())\n",
        "tweets_en = tweets_en.withColumn(\"rank\", F.row_number().over(window))\n",
        "tweets_filtered = tweets_en.filter(F.col(\"rank\") <= 20).drop(\"rank\")"
      ],
      "metadata": {
        "id": "3jkN_YbEKD1n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only users present in tweets_filtered\n",
        "user_features = (\n",
        "    user_features_0\n",
        "    .join(\n",
        "        tweets_filtered.select(\"author_id\").distinct(),\n",
        "        user_features_0.id == tweets_filtered.author_id,\n",
        "        how=\"left_semi\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "ReT62hDHpGh_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join tweets with their users' labels\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "tweet_features = (\n",
        "    tweets_filtered\n",
        "    .join(\n",
        "        user_features.select(\"id\", \"label\"),\n",
        "        tweets_filtered.author_id == user_features.id,\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .drop(user_features.id)\n",
        ")"
      ],
      "metadata": {
        "id": "1G0aiDzGtSvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = \"/content/drive/MyDrive/twibot-22/processed\"\n",
        "\n",
        "users_labeled.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"user_data.parquet\"))\n",
        "user_features.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"user_features.parquet\"))\n",
        "tweets_selected.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"tweet_data.parquet\"))"
      ],
      "metadata": {
        "id": "yBf91c6ai7so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrsnmYvXKIRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}