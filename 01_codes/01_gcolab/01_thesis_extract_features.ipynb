{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fV-2Mc6kjhr3GdesgLaaXJLp6qV5bBC9",
      "authorship_tag": "ABX9TyOGAIET+c9U7mDiSFH4uzYH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julwdo/thesis/blob/main/01_codes/01_gcolab/01_thesis_extract_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null # OpenJDK 17\n",
        "!wget --show-progress https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz # Apache Spark 3.5.6 with Hadoop 3 support\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -q --upgrade pyspark==3.5.6"
      ],
      "metadata": {
        "id": "mQ8T-LAUzBeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23820df-fe8f-4521-91f6-e8585e0c2d67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-25 15:12:59--  https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400923510 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.6-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.6-bin-had 100%[===================>] 382.35M  14.1MB/s    in 26s     \n",
            "\n",
            "2026-01-25 15:13:25 (14.7 MB/s) - ‘spark-3.5.6-bin-hadoop3.tgz’ saved [400923510/400923510]\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/317.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 1.0.1 requires pyspark[connect]~=4.0.0, but you have pyspark 3.5.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.5.6-bin-hadoop3'"
      ],
      "metadata": {
        "id": "WHawKcY3TCNK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"BotDetection\")\n",
        "    .master(\"local[*]\")\n",
        "    .getOrCreate()\n",
        "    )\n",
        "spark"
      ],
      "metadata": {
        "id": "hBPmK_AXjToH",
        "outputId": "a8312898-f589-4a50-9be0-6a08055cecd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c4ec3764b60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://247b671cb7d3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BotDetection</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import math\n",
        "from collections import Counter\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.types import StringType, NumericType, BooleanType, ArrayType, FloatType"
      ],
      "metadata": {
        "id": "J-C_Oc4BzG2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "1dvQfYXH_WoT",
        "outputId": "9bb9c38d-4090-415b-f4cb-ece9ce670329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "in_dir = \"/content/drive/MyDrive/twibot-22/raw\""
      ],
      "metadata": {
        "id": "6j6dkdVX825n",
        "outputId": "848887e4-b386-4294-b568-8a7d3a26999f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = spark.read.json(os.path.join(in_dir, \"user.jsonl\"))\n",
        "#users.printSchema()"
      ],
      "metadata": {
        "id": "4ljK4HtA_MmV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "zfqG1CcW_Q1c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_selected = users.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"name\"),\n",
        "    F.col(\"username\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.col(\"description\"),\n",
        "    F.col(\"url\"),\n",
        "    F.col(\"entities.description.cashtags\"),\n",
        "    F.col(\"entities.description.hashtags\"),\n",
        "    F.col(\"entities.description.mentions\"),\n",
        "    F.col(\"entities.description.urls\"),\n",
        "    F.col(\"location\"),\n",
        "    F.col(\"pinned_tweet_id\"),\n",
        "    F.col(\"profile_image_url\"),\n",
        "    F.col(\"protected\"),\n",
        "    F.col(\"public_metrics.followers_count\"),\n",
        "    F.col(\"public_metrics.following_count\"),\n",
        "    F.col(\"public_metrics.listed_count\"),\n",
        "    F.col(\"public_metrics.tweet_count\"),\n",
        "    F.col(\"verified\")\n",
        "    )"
      ],
      "metadata": {
        "id": "GQAYasduAYqH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ce5ND56SEn8R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "m1nb1FybEtUp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = spark.read.csv(os.path.join(in_dir, \"label.csv\"), header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sDJSz4DuE6_2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "2S3i6OraGnzV",
        "outputId": "623dcac0-1edc-4747-b24f-b7c5b4200f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|id                  |label|\n",
            "+--------------------+-----+\n",
            "|u1217628182611927040|human|\n",
            "|u2664730894         |human|\n",
            "|u1266703520205549568|human|\n",
            "|u1089159225148882949|human|\n",
            "|u36741729           |bot  |\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_labeled = users_selected.join(labels, users_selected.id == labels.id, \"left\").drop(labels.id)"
      ],
      "metadata": {
        "id": "Dx7pGZ1rGpSJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_labeled.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "yxJV0qKaG_Et"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#users_labeled.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in users_labeled.columns]).show()"
      ],
      "metadata": {
        "id": "e29uv2D-P3Zz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(text):\n",
        "  return sia.polarity_scores(text)[\"compound\"]\n",
        "\n",
        "vader_udf = F.udf(vader_sentiment, FloatType())"
      ],
      "metadata": {
        "id": "hR9nb9Q6P7CJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shannon_entropy(string):\n",
        "    if string.strip() == \"\":\n",
        "        return 0.0\n",
        "    counts = Counter(string)\n",
        "    length = len(string)\n",
        "    return -sum((count/length) * math.log2(count/length) for count in counts.values())\n",
        "\n",
        "entropy_udf = F.udf(shannon_entropy, FloatType())"
      ],
      "metadata": {
        "id": "T9Gc6ww0beC5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = F.current_timestamp()"
      ],
      "metadata": {
        "id": "3JkuBNxKOLqc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features_0 = users_labeled.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"name\"),\n",
        "    F.col(\"username\"),\n",
        "    F.length(F.col(\"name\")).alias(\"name_length\"),\n",
        "    F.length(F.col(\"username\")).alias(\"username_length\"),\n",
        "    (F.length(F.col(\"username\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_length_ratio\"),\n",
        "    F.col(\"description\"),\n",
        "#    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"description\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"description\"),\n",
        "    F.length(F.col(\"description\")).alias(\"description_length\"),\n",
        "    F.when(F.col(\"name\") == \"\", False).otherwise(True).alias(\"has_name\"),\n",
        "    F.when(F.col(\"username\") == \"\", False).otherwise(True).alias(\"has_username\"),\n",
        "    F.when(F.col(\"description\") == \"\", False).otherwise(True).alias(\"has_description\"),\n",
        "    F.when(F.col(\"url\") == \"\", False).otherwise(True).alias(\"has_url\"),\n",
        "    F.when(F.col(\"location\").isNull() | (F.col(\"location\") == \"\"), False).otherwise(True).alias(\"has_location\"),\n",
        "    F.when(F.col(\"pinned_tweet_id\").isNull(), False).otherwise(True).alias(\"has_pinned_tweet\"),\n",
        "    F.col(\"name\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_name\"),\n",
        "    F.col(\"description\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_digits_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_digits_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_digits_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_special_chars_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_special_chars_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_special_chars_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"name\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"name_upper_to_lower_ratio\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"username\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"username_upper_to_lower_ratio\"),\n",
        "    entropy_udf(F.col(\"name\")).alias(\"name_entropy\"),\n",
        "    entropy_udf(F.col(\"username\")).alias(\"username_entropy\"),\n",
        "    (F.levenshtein(F.col(\"username\"), F.col(\"name\")) / F.greatest(F.length(F.col(\"username\")), F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_levenshtein\"),\n",
        "    vader_udf(F.col(\"description\")).alias(\"description_sentiment\"),\n",
        "    F.when(F.col(\"cashtags\").isNotNull(), F.size(F.col(\"cashtags\"))).otherwise(F.lit(0)).alias(\"cashtag_in_description_count\"),\n",
        "    F.when(F.col(\"hashtags\").isNotNull(), F.size(F.col(\"hashtags\"))).otherwise(F.lit(0)).alias(\"hashtag_in_description_count\"),\n",
        "    F.when(F.col(\"mentions\").isNotNull(), F.size(F.col(\"mentions\"))).otherwise(F.lit(0)).alias(\"mention_in_description_count\"),\n",
        "    F.when(F.col(\"urls\").isNotNull(), F.size(F.col(\"urls\"))).otherwise(F.lit(0)).alias(\"url_in_description_count\"),\n",
        "    F.col(\"protected\").alias(\"is_protected\"),\n",
        "    F.col(\"verified\").alias(\"is_verified\"),\n",
        "    F.col(\"created_at\"),\n",
        "    (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\"))).alias(\"account_age_seconds\"),\n",
        "    F.col(\"followers_count\"),\n",
        "    F.col(\"following_count\"),\n",
        "    F.col(\"listed_count\"),\n",
        "    F.col(\"tweet_count\"),\n",
        "    (F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"followers_over_following\"),\n",
        "    (2 * F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"double_followers_over_following\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"following_over_followers\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") ** 2, F.lit(1))).alias(\"following_over_followers_squared\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") + F.col(\"following_count\"), F.lit(1))).alias(\"following_over_total_connections\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"listed_over_followers\"),\n",
        "    (F.col(\"tweet_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"tweets_over_followers\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"tweet_count\"), F.lit(1))).alias(\"listed_over_tweets\"),\n",
        "    (F.col(\"followers_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"follower_rate\"),\n",
        "    (F.col(\"following_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"following_rate\"),\n",
        "    (F.col(\"listed_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"listed_rate\"),\n",
        "    (F.col(\"tweet_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"tweet_rate\"),\n",
        "    F.col(\"label\")\n",
        "    )"
      ],
      "metadata": {
        "id": "S2TklOE1NR4W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = spark.read.json(os.path.join(in_dir, \"tweet_0.jsonl\"))\n",
        "#tweets.printSchema()"
      ],
      "metadata": {
        "id": "BoXGa7V54LOz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "WQcJouz95AqR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_selected = tweets.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"text\"),\n",
        "#    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"text\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"text\"),\n",
        "    F.concat(F.lit(\"u\"), F.col(\"author_id\")).alias(\"author_id\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.col(\"in_reply_to_user_id\"),\n",
        "    F.when(F.col(\"in_reply_to_user_id\").isNull(), False).otherwise(True).cast(\"int\").alias(\"is_reply\"),\n",
        "    F.col(\"lang\"),\n",
        "    F.col(\"possibly_sensitive\").cast(\"int\").alias(\"is_sensitive\"),\n",
        "    F.col(\"public_metrics.like_count\"),\n",
        "    F.col(\"public_metrics.quote_count\"),\n",
        "    F.col(\"public_metrics.reply_count\"),\n",
        "    F.col(\"public_metrics.retweet_count\")\n",
        "    )"
      ],
      "metadata": {
        "id": "YUIgowMCnixE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ksw3FbI0oI30"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Olt6LrVdNQEB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#tweets_selected.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tweets_selected.columns]).show()"
      ],
      "metadata": {
        "id": "nwL2Tp8gNydF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: count non-English tweets per user\n",
        "non_en_count = tweets_selected.groupBy(\"author_id\") \\\n",
        "    .agg(F.sum(F.when(F.col(\"lang\") != \"en\", 1).otherwise(0)).alias(\"non_en_count\"))\n",
        "\n",
        "# Step 2: keep only users with zero non-English tweets\n",
        "users_only_en = non_en_count.filter(F.col(\"non_en_count\") == 0).select(\"author_id\")\n",
        "\n",
        "# Step 3: join back to filter tweets\n",
        "tweets_only_en_users = tweets_selected.join(users_only_en, on=\"author_id\", how=\"inner\") \\\n",
        "    .drop(\"lang\")"
      ],
      "metadata": {
        "id": "MS93mDwo9WD2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter top 20 tweets per author\n",
        "window = Window.partitionBy(\"author_id\").orderBy(F.col(\"created_at\").desc())\n",
        "tweets_only_en_users = tweets_only_en_users.withColumn(\"rank\", F.row_number().over(window))\n",
        "tweets_filtered = tweets_only_en_users.filter(F.col(\"rank\") <= 20).drop(\"rank\")"
      ],
      "metadata": {
        "id": "3jkN_YbEKD1n"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = (\n",
        "    user_features_0\n",
        "    .join(\n",
        "        tweets_filtered.select(\"author_id\").distinct(),\n",
        "        user_features_0.id == tweets_filtered.author_id,\n",
        "        how=\"left_semi\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "ReT62hDHpGh_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = (\n",
        "    tweets_filtered\n",
        "    .join(\n",
        "        user_features.select(\"id\", \"label\"),\n",
        "        tweets_filtered.author_id == user_features.id,\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .drop(user_features.id)\n",
        ")"
      ],
      "metadata": {
        "id": "1G0aiDzGtSvm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = \"/content/drive/MyDrive/twibot-22/processed\"\n",
        "\n",
        "user_features.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"user_features_v1.parquet\"))\n",
        "#tweet_features.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"tweet_features_v1.parquet\"))"
      ],
      "metadata": {
        "id": "yBf91c6ai7so"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = spark.read.csv(os.path.join(in_dir, \"edge.csv\"), header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "7PLv0Ywn73w0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges.printSchema()"
      ],
      "metadata": {
        "id": "HAyPUh0ZvUMO",
        "outputId": "2440831f-f466-42bc-8809-bd3a8a274670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- source_id: string (nullable = true)\n",
            " |-- relation: string (nullable = true)\n",
            " |-- target_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = user_features.select(F.col(\"id\")).dropDuplicates()"
      ],
      "metadata": {
        "id": "calcztlg78C2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges_filtered = (\n",
        "    edges\n",
        "    .join(users.withColumnRenamed(\"id\", \"source_id\"),\n",
        "          on=\"source_id\",\n",
        "          how=\"inner\")\n",
        "    .join(users.withColumnRenamed(\"id\", \"target_id\"),\n",
        "          on=\"target_id\",\n",
        "          how=\"inner\")\n",
        ")"
      ],
      "metadata": {
        "id": "vZDQIBVL97Ou"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges_filtered.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"edges_filtered.parquet\"))"
      ],
      "metadata": {
        "id": "wkl9L-am-CKm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = (\n",
        "    users_labeled\n",
        "    .join(\n",
        "        tweets_filtered.select(\"author_id\").distinct(),\n",
        "        users_labeled.id == tweets_filtered.author_id,\n",
        "        how=\"left_semi\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "user_data.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"user_data.parquet\"))"
      ],
      "metadata": {
        "id": "_sjddvs7wwKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_tweet_features = tweet_features.groupBy(\"author_id\").agg(\n",
        "    F.collect_list(\"text\").alias(\"top_tweets_text\"),\n",
        "    F.collect_list(\"created_at\").alias(\"top_tweets_created_at\"),\n",
        "    F.collect_list(\"is_reply\").alias(\"top_tweets_is_reply\"),\n",
        "    F.collect_list(\"is_sensitive\").alias(\"top_tweets_is_sensitive\"),\n",
        "    F.collect_list(\"like_count\").alias(\"top_tweets_like_count\"),\n",
        "    F.collect_list(\"quote_count\").alias(\"top_tweets_quote_count\"),\n",
        "    F.collect_list(\"reply_count\").alias(\"top_tweets_reply_count\"),\n",
        "    F.collect_list(\"retweet_count\").alias(\"top_tweets_retweet_count\")\n",
        "    )"
      ],
      "metadata": {
        "id": "NTZ2VQq00_Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_user_features = user_features.join(\n",
        "    aggregated_tweet_features,\n",
        "    user_features.id == aggregated_tweet_features.author_id,\n",
        "    how=\"left\"\n",
        ").drop(\"author_id\").cache()"
      ],
      "metadata": {
        "id": "5Ju-GKG22sIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_user_features.write.mode(\"overwrite\").parquet(os.path.join(out_dir, \"enriched_user_features.parquet\"))"
      ],
      "metadata": {
        "id": "TenTK0iQ3L3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7oddoNFQ3Pkf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}