{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nAZMKnYVV-_R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Julia\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\Julia\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import zlib\n",
        "import numpy as np\n",
        "import emoji\n",
        "\n",
        "from collections import Counter\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import textstat\n",
        "from textblob import TextBlob\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "DIGIT_PATTERN = r\"\\d\"\n",
        "SPECIAL_CHAR_PATTERN = r\"[^A-Za-z0-9 ]\"\n",
        "USER_PATTERN = r\"(?<!\\w)@[A-Za-z0-9_]{1,15}\\b\"\n",
        "URL_PATTERN = r\"(https?://[^\\s]+|www\\.[^\\s]+)\"\n",
        "HASHTAG_PATTERN = r\"#\\w+\"\n",
        "CASHTAG_PATTERN = r\"\\$\\w+\"\n",
        "EMAIL_PATTERN = r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b\"\n",
        "\n",
        "FUNCTION_WORDS = {\n",
        "  \"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"if\", \"while\", \"with\", \"to\", \"of\", \"in\", \"on\",\n",
        "  \"for\", \"from\", \"by\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\"\n",
        "}\n",
        "\n",
        "def normalize_entities(text):\n",
        "  if not isinstance(text, str) or text.strip() == \"\":\n",
        "    return text\n",
        "  \n",
        "  text = re.sub(EMAIL_PATTERN, \"<EMAIL>\", text)\n",
        "  text = re.sub(URL_PATTERN, \"<URL>\", text)\n",
        "  text = re.sub(USER_PATTERN, \"<USER>\", text)\n",
        "\n",
        "  return text\n",
        "\n",
        "def extract_text_features(text, is_tweet=False):\n",
        "  if not isinstance(text, str) or text.strip() == \"\":\n",
        "    return {\n",
        "        \"is_present\": False,\n",
        "        \"length\": None,\n",
        "        \"num_words\": None,\n",
        "        \"num_sentences\": None,\n",
        "        \"avg_sentence_length\": None,\n",
        "        \"avg_word_length\": None,\n",
        "        \"std_word_length\": None,\n",
        "        \"unique_word_ratio\": None,\n",
        "        \"guiraud_index\": None,\n",
        "        \"repetition_ratio\": None,\n",
        "        \"hapax_ratio\": None,\n",
        "        \"digit_ratio\": None,\n",
        "        \"uppercase_ratio\": None,\n",
        "        \"lowercase_ratio\": None,\n",
        "        \"special_char_ratio\": None,\n",
        "        \"punctuation_ratio\": None,\n",
        "        \"whitespace_ratio\": None,\n",
        "        \"emoji_count\": None,\n",
        "        \"emoji_ratio\": None,\n",
        "        \"mention_count\": None,\n",
        "        \"contains_mention\": False,\n",
        "        \"url_count\": None,\n",
        "        \"contains_url\": False,\n",
        "        \"hashtag_count\": None,\n",
        "        \"cashtag_count\": None,\n",
        "        \"email_count\": None,\n",
        "        \"contains_bot_word_or_hashtag\": False,\n",
        "        \"contains_ai_hashtag\": False,\n",
        "        \"sentiment\": None,\n",
        "        \"sentiment_abs\": None,\n",
        "        \"sentiment_neutrality\": None,\n",
        "        \"sentiment_subjectivity\": None,\n",
        "        \"flesch_reading_ease\": None,\n",
        "        \"flesch_kincaid_grade\": None,\n",
        "        \"avg_syllables_per_word\": None,\n",
        "        \"polysyllabic_word_ratio\": None,\n",
        "        \"char_entropy\": None,\n",
        "        \"word_entropy\": None,\n",
        "        \"compression_ratio\": None,\n",
        "        \"starts_with_emoji\": False,\n",
        "        \"ends_with_emoji\": False,\n",
        "        \"starts_with_url\": False,\n",
        "        \"ends_with_url\": False,\n",
        "        \"contains_pipe_or_bullet\": False,\n",
        "        \"contains_call_to_action\": False,\n",
        "        \"contains_ai_phrase\": False,\n",
        "        \"function_word_ratio\": None,\n",
        "        \"noun_ratio\": None,\n",
        "        \"verb_ratio\": None,\n",
        "        \"pronoun_ratio\": None,\n",
        "        \"adjective_ratio\": None,\n",
        "        \"contains_repeated_chars\": False,\n",
        "        \"is_retweet\": False,\n",
        "        \"is_quote\": False\n",
        "    }\n",
        "\n",
        "  text = text.strip()\n",
        "  text = normalize_entities(text)\n",
        "  char_len = len(text)\n",
        "\n",
        "  words = word_tokenize(text)\n",
        "  words_lower = [w.lower() for w in words if w.isalpha()]\n",
        "  num_words = len(words_lower)\n",
        "\n",
        "  sentences = sent_tokenize(text)\n",
        "  num_sentences = len(sentences)\n",
        "\n",
        "  # --- A: Presence & length\n",
        "  avg_sentence_length = num_words / num_sentences if num_sentences else None\n",
        "\n",
        "  # --- B: Lexical structure\n",
        "  word_lengths = [len(w) for w in words_lower]\n",
        "  avg_word_length = np.mean(word_lengths) if word_lengths else None\n",
        "  std_word_length = np.std(word_lengths) if word_lengths else None\n",
        "\n",
        "  word_counts = Counter(words_lower)\n",
        "  unique_word_ratio = len(word_counts) / num_words if num_words else None\n",
        "  guiraud_index = len(word_counts) / np.sqrt(num_words) if num_words else None\n",
        "  repetition_ratio = 1 - unique_word_ratio if unique_word_ratio is not None else None\n",
        "  hapax_ratio = sum(1 for w in word_counts if word_counts[w] == 1) / num_words if num_words else None\n",
        "\n",
        "  # --- C: Character composition\n",
        "  digits = len(re.findall(DIGIT_PATTERN, text))\n",
        "  letters = re.findall(r\"[A-Za-z]\", text)\n",
        "  uppercase = sum(1 for c in letters if c.isupper())\n",
        "  lowercase = sum(1 for c in letters if c.islower())\n",
        "  special_chars = len(re.findall(SPECIAL_CHAR_PATTERN, text))\n",
        "  punctuation = sum(1 for c in text if c in string.punctuation)\n",
        "  whitespaces = text.count(\" \")\n",
        "\n",
        "  emoji_count = sum(1 for c in text if c in emoji.EMOJI_DATA)\n",
        "\n",
        "  digit_ratio = digits / char_len\n",
        "  uppercase_ratio = uppercase / len(letters) if letters else None\n",
        "  lowercase_ratio = lowercase / len(letters) if letters else None\n",
        "  special_char_ratio = special_chars / char_len\n",
        "  punctuation_ratio = punctuation / char_len\n",
        "  whitespace_ratio = whitespaces / char_len\n",
        "  emoji_ratio = emoji_count / char_len\n",
        "\n",
        "  # --- D: Token usage\n",
        "  mention_count = text.count(\"<USER>\")\n",
        "  url_count = text.count(\"<URL>\")\n",
        "  hashtag_count = len(re.findall(HASHTAG_PATTERN, text))\n",
        "  cashtag_count = len(re.findall(CASHTAG_PATTERN, text))\n",
        "  email_count = text.count(\"<EMAIL>\")\n",
        "\n",
        "  # --- E: Semantic signals\n",
        "  contains_bot_word_or_hashtag = bool(re.search(r\"(?i)(\\bbot\\b|#\\w*bot\\b)\", text))\n",
        "  contains_ai_hashtag = bool(re.search(r\"(?i)\\b#ai\\b|#\\w+ai\\b\", text))\n",
        "\n",
        "  sentiment = analyzer.polarity_scores(text)[\"compound\"]\n",
        "  sentiment_abs = abs(sentiment)\n",
        "  sentiment_neutrality = 1 - sentiment_abs\n",
        "  \n",
        "  blob = TextBlob(text)\n",
        "  sentiment_subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "  # --- F: Readability\n",
        "  flesch_reading_ease = textstat.flesch_reading_ease(text)\n",
        "  flesch_kincaid_grade = textstat.flesch_kincaid_grade(text)\n",
        "  avg_syllables_per_word = textstat.avg_syllables_per_word(text)\n",
        "  polysyllabic_word_ratio = textstat.polysyllabcount(text) / num_words if num_words else None\n",
        "\n",
        "  # --- G: Entropy & compression\n",
        "  char_entropy = entropy(list(Counter(text).values()), base=2)\n",
        "  word_entropy = entropy(list(word_counts.values()), base=2) if word_counts else None\n",
        "  avg_word_repetition = np.mean(list(word_counts.values())) if word_counts else None\n",
        "  compression_ratio = len(zlib.compress(text.encode(\"utf-8\"))) / char_len\n",
        "\n",
        "  # --- H: Template indicators\n",
        "  starts_with_emoji = text[0] in emoji.EMOJI_DATA\n",
        "  ends_with_emoji = text[-1] in emoji.EMOJI_DATA\n",
        "  starts_with_url = text.startswith(\"<URL>\")\n",
        "  ends_with_url = text.endswith(\"<URL>\")\n",
        "  contains_pipe_or_bullet = bool(re.search(r\"\\s[|•]\\s\", text))\n",
        "  contains_call_to_action = bool(re.search(r\"(?i)\\b(follow|dm|click|join|subscribe|contact|call|buy|giveaway|free|win|retweet|apply)\\b\", text))\n",
        "  contains_ai_phrase = bool(re.search(r\"(?i)\\b(powered by AI|autogenerated|generated by AI|AI assistant)\\b\", text))\n",
        "\n",
        "  # --- I: Grammatical composition (self-reference & POS)\n",
        "  function_word_ratio = sum(w in FUNCTION_WORDS for w in words_lower) / num_words if num_words else None\n",
        "\n",
        "  pos_tags = pos_tag(words_lower)\n",
        "  pos_counts = Counter(tag for _, tag in pos_tags)\n",
        "\n",
        "  noun_ratio = sum(pos_counts[t] for t in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]) / num_words if num_words else None\n",
        "  verb_ratio = sum(pos_counts[t] for t in [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]) / num_words if num_words else None\n",
        "  pronoun_ratio = sum(pos_counts[t] for t in [\"PRP\", \"PRP$\"]) / num_words if num_words else None\n",
        "  adjective_ratio = sum(pos_counts[t] for t in [\"JJ\", \"JJR\", \"JJS\"]) / num_words if num_words else None\n",
        " \n",
        "  # --- J: Noise & stylistic irregularities\n",
        "  contains_repeated_chars = bool(re.search(r'(.)\\1{2,}', text))\n",
        "\n",
        "  # --- K: Platform-specific discourse markers (tweets only)\n",
        "  if is_tweet:\n",
        "    is_retweet = bool(re.match(r'^RT\\s+<USER>', text))\n",
        "    is_quote = bool(re.match(r'^(QT|“|\")', text))\n",
        "  else:\n",
        "    is_retweet = None\n",
        "    is_quote = None\n",
        "\n",
        "  return {\n",
        "      \"is_present\": True,\n",
        "      \"length\": char_len,\n",
        "      \"num_words\": num_words,\n",
        "      \"num_sentences\": num_sentences,\n",
        "      \"avg_sentence_length\": avg_sentence_length,\n",
        "      \"avg_word_length\": avg_word_length,\n",
        "      \"std_word_length\": std_word_length,\n",
        "      \"unique_word_ratio\": unique_word_ratio,\n",
        "      \"guiraud_index\": guiraud_index,\n",
        "      \"repetition_ratio\": repetition_ratio,\n",
        "      \"hapax_ratio\": hapax_ratio,\n",
        "      \"digit_ratio\": digit_ratio,\n",
        "      \"uppercase_ratio\": uppercase_ratio,\n",
        "      \"lowercase_ratio\": lowercase_ratio,\n",
        "      \"special_char_ratio\": special_char_ratio,\n",
        "      \"punctuation_ratio\": punctuation_ratio,\n",
        "      \"whitespace_ratio\": whitespace_ratio,\n",
        "      \"emoji_count\": emoji_count,\n",
        "      \"emoji_ratio\": emoji_ratio,\n",
        "      \"mention_count\": mention_count,\n",
        "      \"contains_mention\": mention_count > 0,\n",
        "      \"url_count\": url_count,\n",
        "      \"contains_url\": url_count > 0,\n",
        "      \"hashtag_count\": hashtag_count,\n",
        "      \"cashtag_count\": cashtag_count,\n",
        "      \"email_count\": email_count,\n",
        "      \"contains_bot_word_or_hashtag\": contains_bot_word_or_hashtag,\n",
        "      \"contains_ai_hashtag\": contains_ai_hashtag,\n",
        "      \"sentiment\": sentiment,\n",
        "      \"sentiment_abs\": sentiment_abs,\n",
        "      \"sentiment_neutrality\": sentiment_neutrality,\n",
        "      \"sentiment_subjectivity\": sentiment_subjectivity,\n",
        "      \"flesch_reading_ease\": flesch_reading_ease,\n",
        "      \"flesch_kincaid_grade\": flesch_kincaid_grade,\n",
        "      \"avg_syllables_per_word\": avg_syllables_per_word,\n",
        "      \"polysyllabic_word_ratio\": polysyllabic_word_ratio,\n",
        "      \"char_entropy\": char_entropy,\n",
        "      \"word_entropy\": word_entropy,\n",
        "      \"avg_word_repetition\": avg_word_repetition,\n",
        "      \"compression_ratio\": compression_ratio,\n",
        "      \"starts_with_emoji\": starts_with_emoji,\n",
        "      \"ends_with_emoji\": ends_with_emoji,\n",
        "      \"starts_with_url\": starts_with_url,\n",
        "      \"ends_with_url\": ends_with_url,\n",
        "      \"contains_pipe_or_bullet\": contains_pipe_or_bullet,\n",
        "      \"contains_call_to_action\": contains_call_to_action,\n",
        "      \"contains_ai_phrase\": contains_ai_phrase,\n",
        "      \"function_word_ratio\": function_word_ratio,\n",
        "      \"noun_ratio\": noun_ratio,\n",
        "      \"verb_ratio\": verb_ratio,\n",
        "      \"pronoun_ratio\": pronoun_ratio,\n",
        "      \"adjective_ratio\": adjective_ratio,\n",
        "      \"contains_repeated_chars\": contains_repeated_chars,\n",
        "      \"is_retweet\": is_retweet,\n",
        "      \"is_quote\": is_quote\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from emoji import demojize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "USER_PATTERN = r\"(?<!\\w)@[A-Za-z0-9_]{1,15}\\b\"\n",
        "URL_PATTERN = r\"(https?://[^\\s]+|www\\.[^\\s]+)\"\n",
        "EMAIL_PATTERN = r\"\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b\"\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "def normalize_entities(text):\n",
        "  if not isinstance(text, str) or text.strip() == \"\":\n",
        "    return text\n",
        "  \n",
        "  text = re.sub(EMAIL_PATTERN, \"<EMAIL>\", text)\n",
        "  text = re.sub(URL_PATTERN, \"<URL>\", text)\n",
        "  text = re.sub(USER_PATTERN, \"<USER>\", text)\n",
        "\n",
        "  return text\n",
        "\n",
        "def normalize_token(token):\n",
        "    token = token.replace(\"’\", \"'\").replace(\"…\", \"...\")\n",
        "\n",
        "    if token == \"<USER>\":\n",
        "        return \"@USER\"\n",
        "    if token == \"<URL>\":\n",
        "        return \"HTTPURL\"\n",
        "    if len(token) == 1:\n",
        "        return demojize(token)\n",
        "\n",
        "    return token\n",
        "\n",
        "def normalize_text(text):\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    text = text.strip()\n",
        "    text = normalize_entities(text)\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    norm_tweet = \" \".join(normalize_token(t) for t in tokens)\n",
        "\n",
        "    # contractions\n",
        "    norm_tweet = (\n",
        "        norm_tweet.replace(\"cannot \", \"can not \")\n",
        "                  .replace(\" n't \", \" n't \")\n",
        "                  .replace(\"ca n't\", \"can't\")\n",
        "                  .replace(\"ai n't\", \"ain't\")\n",
        "    )\n",
        "\n",
        "    # verb contractions\n",
        "    norm_tweet = (\n",
        "        norm_tweet.replace(\" 'm \", \" 'm \")\n",
        "                  .replace(\" 're \", \" 're \")\n",
        "                  .replace(\" 's \", \" 's \")\n",
        "                  .replace(\" 'll \", \" 'll \")\n",
        "                  .replace(\" 'd \", \" 'd \")\n",
        "                  .replace(\" 've \", \" 've \")\n",
        "    )\n",
        "\n",
        "    # time expressions\n",
        "    norm_tweet = (\n",
        "        norm_tweet.replace(\" p . m .\", \" p.m.\")\n",
        "                  .replace(\" p . m \", \" p.m \")\n",
        "                  .replace(\" a . m .\", \" a.m.\")\n",
        "                  .replace(\" a . m \", \" a.m \")\n",
        "    )\n",
        "\n",
        "    return \" \".join(norm_tweet.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class SentenceEmbedder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model_name=\"vinai/bertweet-base\"):\n",
        "      self.model_name = model_name\n",
        "      self.model = AutoModel.from_pretrained(self.model_name)\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "      self.model.to(device)\n",
        "      self.model.eval()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "    def transform(self, X):\n",
        "      if isinstance(X, pd.Series):\n",
        "        X = X.values\n",
        "\n",
        "      out = np.empty((len(X), 1), dtype=object)\n",
        "      batch_size = 1024\n",
        "\n",
        "      loader = DataLoader(\n",
        "          X,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=False\n",
        "          )\n",
        "      embeddings = []\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Embedding text\"):\n",
        "          inputs = self.tokenizer(\n",
        "              batch,\n",
        "              padding=True,\n",
        "              truncation=True,\n",
        "              max_length=64,\n",
        "              return_tensors=\"pt\"\n",
        "              )\n",
        "          inputs = {k: v.to(device) for k, v in inputs.items()}  # move tensors to GPU\n",
        "\n",
        "          outputs = self.model(**inputs)\n",
        "          batch_embeddings = outputs.last_hidden_state[:, 0, :]  # (n_samples, 768)\n",
        "          embeddings.append(batch_embeddings.cpu())\n",
        "\n",
        "      embeddings = torch.cat(embeddings, dim=0)  # shape: (N, 768)\n",
        "      out[:, 0] = list(embeddings.numpy())  # each row is a 768-D array\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c5MFnqshVh3w"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name_length</th>\n",
              "      <th>username_length</th>\n",
              "      <th>username_name_length_ratio</th>\n",
              "      <th>description</th>\n",
              "      <th>description_length</th>\n",
              "      <th>has_name</th>\n",
              "      <th>has_username</th>\n",
              "      <th>has_description</th>\n",
              "      <th>has_url</th>\n",
              "      <th>has_location</th>\n",
              "      <th>has_pinned_tweet</th>\n",
              "      <th>has_bot_word_in_name</th>\n",
              "      <th>has_bot_word_in_description</th>\n",
              "      <th>ratio_digits_in_name</th>\n",
              "      <th>ratio_digits_in_username</th>\n",
              "      <th>ratio_digits_in_description</th>\n",
              "      <th>ratio_special_chars_in_name</th>\n",
              "      <th>ratio_special_chars_in_username</th>\n",
              "      <th>ratio_special_chars_in_description</th>\n",
              "      <th>name_upper_to_lower_ratio</th>\n",
              "      <th>username_upper_to_lower_ratio</th>\n",
              "      <th>name_entropy</th>\n",
              "      <th>username_entropy</th>\n",
              "      <th>username_name_levenshtein</th>\n",
              "      <th>description_sentiment</th>\n",
              "      <th>cashtag_in_description_count</th>\n",
              "      <th>hashtag_in_description_count</th>\n",
              "      <th>mention_in_description_count</th>\n",
              "      <th>url_in_description_count</th>\n",
              "      <th>is_protected</th>\n",
              "      <th>is_verified</th>\n",
              "      <th>created_at</th>\n",
              "      <th>account_age_seconds</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>listed_count</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>followers_over_following</th>\n",
              "      <th>double_followers_over_following</th>\n",
              "      <th>following_over_followers</th>\n",
              "      <th>following_over_followers_squared</th>\n",
              "      <th>following_over_total_connections</th>\n",
              "      <th>listed_over_followers</th>\n",
              "      <th>tweets_over_followers</th>\n",
              "      <th>listed_over_tweets</th>\n",
              "      <th>follower_rate</th>\n",
              "      <th>following_rate</th>\n",
              "      <th>listed_rate</th>\n",
              "      <th>tweet_rate</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1000115670657318912</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>Open source tool for data &amp; models versioning for ML projects. Join our stellar community https://t.co/vBp8rcV4bf for help, support and insights.</td>\n",
              "      <td>145</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013793</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062069</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2018-05-25 20:45:31+00:00</td>\n",
              "      <td>241981329</td>\n",
              "      <td>3488</td>\n",
              "      <td>325</td>\n",
              "      <td>79</td>\n",
              "      <td>911</td>\n",
              "      <td>10.732308</td>\n",
              "      <td>21.464615</td>\n",
              "      <td>0.093177</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.085235</td>\n",
              "      <td>0.022649</td>\n",
              "      <td>0.261181</td>\n",
              "      <td>0.086718</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.264715e-07</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1000483839800627200</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>Theoretical biologist and advisor to data scientists. I have published in evolution, biochemistry, infectious disease, economics, education. Opinions my own.</td>\n",
              "      <td>157</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044586</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3.022055</td>\n",
              "      <td>2.845351</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2018-05-26 21:08:30+00:00</td>\n",
              "      <td>241893550</td>\n",
              "      <td>2563</td>\n",
              "      <td>458</td>\n",
              "      <td>60</td>\n",
              "      <td>2002</td>\n",
              "      <td>5.596070</td>\n",
              "      <td>11.192140</td>\n",
              "      <td>0.178697</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.151605</td>\n",
              "      <td>0.023410</td>\n",
              "      <td>0.781116</td>\n",
              "      <td>0.029970</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.480430e-07</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  name_length  username_length  \\\n",
              "0  u1000115670657318912            4                6   \n",
              "1  u1000483839800627200           12               11   \n",
              "\n",
              "   username_name_length_ratio  \\\n",
              "0                    1.500000   \n",
              "1                    0.916667   \n",
              "\n",
              "                                                                                                                                                     description  \\\n",
              "0              Open source tool for data & models versioning for ML projects. Join our stellar community https://t.co/vBp8rcV4bf for help, support and insights.   \n",
              "1  Theoretical biologist and advisor to data scientists. I have published in evolution, biochemistry, infectious disease, economics, education. Opinions my own.   \n",
              "\n",
              "   description_length  has_name  has_username  has_description  has_url  \\\n",
              "0                 145      True          True             True    False   \n",
              "1                 157      True          True             True     True   \n",
              "\n",
              "   has_location  has_pinned_tweet  has_bot_word_in_name  \\\n",
              "0          True              True                 False   \n",
              "1          True              True                 False   \n",
              "\n",
              "   has_bot_word_in_description  ratio_digits_in_name  \\\n",
              "0                        False                   0.0   \n",
              "1                        False                   0.0   \n",
              "\n",
              "   ratio_digits_in_username  ratio_digits_in_description  \\\n",
              "0                       0.0                     0.013793   \n",
              "1                       0.0                     0.000000   \n",
              "\n",
              "   ratio_special_chars_in_name  ratio_special_chars_in_username  \\\n",
              "0                         0.25                              0.0   \n",
              "1                         0.00                              0.0   \n",
              "\n",
              "   ratio_special_chars_in_description  name_upper_to_lower_ratio  \\\n",
              "0                            0.062069                   3.000000   \n",
              "1                            0.044586                   0.222222   \n",
              "\n",
              "   username_upper_to_lower_ratio  name_entropy  username_entropy  \\\n",
              "0                       1.000000      2.000000          2.584963   \n",
              "1                       0.222222      3.022055          2.845351   \n",
              "\n",
              "   username_name_levenshtein  description_sentiment  \\\n",
              "0                   0.666667                  0.765   \n",
              "1                   0.083333                  0.000   \n",
              "\n",
              "   cashtag_in_description_count  hashtag_in_description_count  \\\n",
              "0                             0                             0   \n",
              "1                             0                             0   \n",
              "\n",
              "   mention_in_description_count  url_in_description_count  is_protected  \\\n",
              "0                             0                         1         False   \n",
              "1                             0                         0         False   \n",
              "\n",
              "   is_verified                 created_at  account_age_seconds  \\\n",
              "0        False  2018-05-25 20:45:31+00:00            241981329   \n",
              "1        False  2018-05-26 21:08:30+00:00            241893550   \n",
              "\n",
              "   followers_count  following_count  listed_count  tweet_count  \\\n",
              "0             3488              325            79          911   \n",
              "1             2563              458            60         2002   \n",
              "\n",
              "   followers_over_following  double_followers_over_following  \\\n",
              "0                 10.732308                        21.464615   \n",
              "1                  5.596070                        11.192140   \n",
              "\n",
              "   following_over_followers  following_over_followers_squared  \\\n",
              "0                  0.093177                          0.000027   \n",
              "1                  0.178697                          0.000070   \n",
              "\n",
              "   following_over_total_connections  listed_over_followers  \\\n",
              "0                          0.085235               0.022649   \n",
              "1                          0.151605               0.023410   \n",
              "\n",
              "   tweets_over_followers  listed_over_tweets  follower_rate  following_rate  \\\n",
              "0               0.261181            0.086718       0.000014        0.000001   \n",
              "1               0.781116            0.029970       0.000011        0.000002   \n",
              "\n",
              "    listed_rate  tweet_rate  label  \n",
              "0  3.264715e-07    0.000004  human  \n",
              "1  2.480430e-07    0.000008  human  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_features = pd.read_parquet(f\"../../02_data/user_features_v1.parquet\", engine='pyarrow')\n",
        "user_features.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10mbjUiEKZ1i",
        "outputId": "00a271e3-fb67-4ec6-dfa8-bced32fe7b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset contains 99967 rows and 51 columns.\n"
          ]
        }
      ],
      "source": [
        "n_rows, n_columns = user_features.shape\n",
        "print(f\"The dataset contains {n_rows} rows and {n_columns} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_drop = [\"description_length\", \"has_description\",\n",
        "                   \"has_bot_word_in_description\", \"ratio_digits_in_description\",\n",
        "                   \"ratio_special_chars_in_description\", \"description_sentiment\",\n",
        "                   \"cashtag_in_description_count\", \"hashtag_in_description_count\",\n",
        "                   \"mention_in_description_count\", \"url_in_description_count\"]\n",
        "\n",
        "user_features = user_features.drop(columns=columns_to_drop)\n",
        "\n",
        "user_features['label'] = user_features['label'].map({'human': 0, 'bot': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name_length</th>\n",
              "      <th>username_length</th>\n",
              "      <th>username_name_length_ratio</th>\n",
              "      <th>description</th>\n",
              "      <th>has_name</th>\n",
              "      <th>has_username</th>\n",
              "      <th>has_url</th>\n",
              "      <th>has_location</th>\n",
              "      <th>has_pinned_tweet</th>\n",
              "      <th>has_bot_word_in_name</th>\n",
              "      <th>ratio_digits_in_name</th>\n",
              "      <th>ratio_digits_in_username</th>\n",
              "      <th>ratio_special_chars_in_name</th>\n",
              "      <th>ratio_special_chars_in_username</th>\n",
              "      <th>name_upper_to_lower_ratio</th>\n",
              "      <th>username_upper_to_lower_ratio</th>\n",
              "      <th>name_entropy</th>\n",
              "      <th>username_entropy</th>\n",
              "      <th>username_name_levenshtein</th>\n",
              "      <th>is_protected</th>\n",
              "      <th>is_verified</th>\n",
              "      <th>created_at</th>\n",
              "      <th>account_age_seconds</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>listed_count</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>followers_over_following</th>\n",
              "      <th>double_followers_over_following</th>\n",
              "      <th>following_over_followers</th>\n",
              "      <th>following_over_followers_squared</th>\n",
              "      <th>following_over_total_connections</th>\n",
              "      <th>listed_over_followers</th>\n",
              "      <th>tweets_over_followers</th>\n",
              "      <th>listed_over_tweets</th>\n",
              "      <th>follower_rate</th>\n",
              "      <th>following_rate</th>\n",
              "      <th>listed_rate</th>\n",
              "      <th>tweet_rate</th>\n",
              "      <th>label</th>\n",
              "      <th>desc_is_present</th>\n",
              "      <th>desc_length</th>\n",
              "      <th>desc_num_words</th>\n",
              "      <th>desc_num_sentences</th>\n",
              "      <th>desc_avg_sentence_length</th>\n",
              "      <th>desc_avg_word_length</th>\n",
              "      <th>desc_std_word_length</th>\n",
              "      <th>desc_unique_word_ratio</th>\n",
              "      <th>desc_guiraud_index</th>\n",
              "      <th>desc_repetition_ratio</th>\n",
              "      <th>desc_hapax_ratio</th>\n",
              "      <th>desc_digit_ratio</th>\n",
              "      <th>desc_uppercase_ratio</th>\n",
              "      <th>desc_lowercase_ratio</th>\n",
              "      <th>desc_special_char_ratio</th>\n",
              "      <th>desc_punctuation_ratio</th>\n",
              "      <th>desc_whitespace_ratio</th>\n",
              "      <th>desc_emoji_count</th>\n",
              "      <th>desc_emoji_ratio</th>\n",
              "      <th>desc_mention_count</th>\n",
              "      <th>desc_contains_mention</th>\n",
              "      <th>desc_url_count</th>\n",
              "      <th>desc_contains_url</th>\n",
              "      <th>desc_hashtag_count</th>\n",
              "      <th>desc_cashtag_count</th>\n",
              "      <th>desc_email_count</th>\n",
              "      <th>desc_contains_bot_word_or_hashtag</th>\n",
              "      <th>desc_contains_ai_hashtag</th>\n",
              "      <th>desc_sentiment</th>\n",
              "      <th>desc_sentiment_abs</th>\n",
              "      <th>desc_sentiment_neutrality</th>\n",
              "      <th>desc_sentiment_subjectivity</th>\n",
              "      <th>desc_flesch_reading_ease</th>\n",
              "      <th>desc_flesch_kincaid_grade</th>\n",
              "      <th>desc_avg_syllables_per_word</th>\n",
              "      <th>desc_polysyllabic_word_ratio</th>\n",
              "      <th>desc_char_entropy</th>\n",
              "      <th>desc_word_entropy</th>\n",
              "      <th>desc_avg_word_repetition</th>\n",
              "      <th>desc_compression_ratio</th>\n",
              "      <th>desc_starts_with_emoji</th>\n",
              "      <th>desc_ends_with_emoji</th>\n",
              "      <th>desc_starts_with_url</th>\n",
              "      <th>desc_ends_with_url</th>\n",
              "      <th>desc_contains_pipe_or_bullet</th>\n",
              "      <th>desc_contains_call_to_action</th>\n",
              "      <th>desc_contains_ai_phrase</th>\n",
              "      <th>desc_function_word_ratio</th>\n",
              "      <th>desc_noun_ratio</th>\n",
              "      <th>desc_verb_ratio</th>\n",
              "      <th>desc_pronoun_ratio</th>\n",
              "      <th>desc_adjective_ratio</th>\n",
              "      <th>desc_contains_repeated_chars</th>\n",
              "      <th>desc_is_retweet</th>\n",
              "      <th>desc_is_quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1000115670657318912</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>Open source tool for data &amp; models versioning for ML projects. Join our stellar community https://t.co/vBp8rcV4bf for help, support and insights.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.584963</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2018-05-25 20:45:31+00:00</td>\n",
              "      <td>241981329</td>\n",
              "      <td>3488</td>\n",
              "      <td>325</td>\n",
              "      <td>79</td>\n",
              "      <td>911</td>\n",
              "      <td>10.732308</td>\n",
              "      <td>21.464615</td>\n",
              "      <td>0.093177</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.085235</td>\n",
              "      <td>0.022649</td>\n",
              "      <td>0.261181</td>\n",
              "      <td>0.086718</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.264715e-07</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>127.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.05</td>\n",
              "      <td>2.312466</td>\n",
              "      <td>0.9</td>\n",
              "      <td>4.024922</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069307</td>\n",
              "      <td>0.930693</td>\n",
              "      <td>0.047244</td>\n",
              "      <td>0.047244</td>\n",
              "      <td>0.157480</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.375</td>\n",
              "      <td>57.095000</td>\n",
              "      <td>7.78</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.407766</td>\n",
              "      <td>4.084184</td>\n",
              "      <td>1.111111</td>\n",
              "      <td>0.889764</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.15</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1000483839800627200</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>Theoretical biologist and advisor to data scientists. I have published in evolution, biochemistry, infectious disease, economics, education. Opinions my own.</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3.022055</td>\n",
              "      <td>2.845351</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2018-05-26 21:08:30+00:00</td>\n",
              "      <td>241893550</td>\n",
              "      <td>2563</td>\n",
              "      <td>458</td>\n",
              "      <td>60</td>\n",
              "      <td>2002</td>\n",
              "      <td>5.596070</td>\n",
              "      <td>11.192140</td>\n",
              "      <td>0.178697</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.151605</td>\n",
              "      <td>0.023410</td>\n",
              "      <td>0.781116</td>\n",
              "      <td>0.029970</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.480430e-07</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>157.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>6.55</td>\n",
              "      <td>3.442020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.472136</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022901</td>\n",
              "      <td>0.977099</td>\n",
              "      <td>0.044586</td>\n",
              "      <td>0.044586</td>\n",
              "      <td>0.121019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.550</td>\n",
              "      <td>-15.661667</td>\n",
              "      <td>17.10</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.234203</td>\n",
              "      <td>4.321928</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.789809</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.15</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  name_length  username_length  \\\n",
              "0  u1000115670657318912            4                6   \n",
              "1  u1000483839800627200           12               11   \n",
              "\n",
              "   username_name_length_ratio  \\\n",
              "0                    1.500000   \n",
              "1                    0.916667   \n",
              "\n",
              "                                                                                                                                                     description  \\\n",
              "0              Open source tool for data & models versioning for ML projects. Join our stellar community https://t.co/vBp8rcV4bf for help, support and insights.   \n",
              "1  Theoretical biologist and advisor to data scientists. I have published in evolution, biochemistry, infectious disease, economics, education. Opinions my own.   \n",
              "\n",
              "   has_name  has_username  has_url  has_location  has_pinned_tweet  \\\n",
              "0      True          True    False          True              True   \n",
              "1      True          True     True          True              True   \n",
              "\n",
              "   has_bot_word_in_name  ratio_digits_in_name  ratio_digits_in_username  \\\n",
              "0                 False                   0.0                       0.0   \n",
              "1                 False                   0.0                       0.0   \n",
              "\n",
              "   ratio_special_chars_in_name  ratio_special_chars_in_username  \\\n",
              "0                         0.25                              0.0   \n",
              "1                         0.00                              0.0   \n",
              "\n",
              "   name_upper_to_lower_ratio  username_upper_to_lower_ratio  name_entropy  \\\n",
              "0                   3.000000                       1.000000      2.000000   \n",
              "1                   0.222222                       0.222222      3.022055   \n",
              "\n",
              "   username_entropy  username_name_levenshtein  is_protected  is_verified  \\\n",
              "0          2.584963                   0.666667         False        False   \n",
              "1          2.845351                   0.083333         False        False   \n",
              "\n",
              "                  created_at  account_age_seconds  followers_count  \\\n",
              "0  2018-05-25 20:45:31+00:00            241981329             3488   \n",
              "1  2018-05-26 21:08:30+00:00            241893550             2563   \n",
              "\n",
              "   following_count  listed_count  tweet_count  followers_over_following  \\\n",
              "0              325            79          911                 10.732308   \n",
              "1              458            60         2002                  5.596070   \n",
              "\n",
              "   double_followers_over_following  following_over_followers  \\\n",
              "0                        21.464615                  0.093177   \n",
              "1                        11.192140                  0.178697   \n",
              "\n",
              "   following_over_followers_squared  following_over_total_connections  \\\n",
              "0                          0.000027                          0.085235   \n",
              "1                          0.000070                          0.151605   \n",
              "\n",
              "   listed_over_followers  tweets_over_followers  listed_over_tweets  \\\n",
              "0               0.022649               0.261181            0.086718   \n",
              "1               0.023410               0.781116            0.029970   \n",
              "\n",
              "   follower_rate  following_rate   listed_rate  tweet_rate  label  \\\n",
              "0       0.000014        0.000001  3.264715e-07    0.000004      0   \n",
              "1       0.000011        0.000002  2.480430e-07    0.000008      0   \n",
              "\n",
              "   desc_is_present  desc_length  desc_num_words  desc_num_sentences  \\\n",
              "0             True        127.0            20.0                 2.0   \n",
              "1             True        157.0            20.0                 3.0   \n",
              "\n",
              "   desc_avg_sentence_length  desc_avg_word_length  desc_std_word_length  \\\n",
              "0                 10.000000                  5.05              2.312466   \n",
              "1                  6.666667                  6.55              3.442020   \n",
              "\n",
              "   desc_unique_word_ratio  desc_guiraud_index  desc_repetition_ratio  \\\n",
              "0                     0.9            4.024922                    0.1   \n",
              "1                     1.0            4.472136                    0.0   \n",
              "\n",
              "   desc_hapax_ratio  desc_digit_ratio  desc_uppercase_ratio  \\\n",
              "0              0.85               0.0              0.069307   \n",
              "1              1.00               0.0              0.022901   \n",
              "\n",
              "   desc_lowercase_ratio  desc_special_char_ratio  desc_punctuation_ratio  \\\n",
              "0              0.930693                 0.047244                0.047244   \n",
              "1              0.977099                 0.044586                0.044586   \n",
              "\n",
              "   desc_whitespace_ratio  desc_emoji_count  desc_emoji_ratio  \\\n",
              "0               0.157480               0.0               0.0   \n",
              "1               0.121019               0.0               0.0   \n",
              "\n",
              "   desc_mention_count  desc_contains_mention  desc_url_count  \\\n",
              "0                 0.0                  False             1.0   \n",
              "1                 0.0                  False             0.0   \n",
              "\n",
              "   desc_contains_url  desc_hashtag_count  desc_cashtag_count  \\\n",
              "0               True                 0.0                 0.0   \n",
              "1              False                 0.0                 0.0   \n",
              "\n",
              "   desc_email_count  desc_contains_bot_word_or_hashtag  \\\n",
              "0               0.0                              False   \n",
              "1               0.0                              False   \n",
              "\n",
              "   desc_contains_ai_hashtag  desc_sentiment  desc_sentiment_abs  \\\n",
              "0                     False           0.765               0.765   \n",
              "1                     False           0.000               0.000   \n",
              "\n",
              "   desc_sentiment_neutrality  desc_sentiment_subjectivity  \\\n",
              "0                      0.235                        0.375   \n",
              "1                      1.000                        0.550   \n",
              "\n",
              "   desc_flesch_reading_ease  desc_flesch_kincaid_grade  \\\n",
              "0                 57.095000                       7.78   \n",
              "1                -15.661667                      17.10   \n",
              "\n",
              "   desc_avg_syllables_per_word  desc_polysyllabic_word_ratio  \\\n",
              "0                         1.65                           0.1   \n",
              "1                         2.55                           0.5   \n",
              "\n",
              "   desc_char_entropy  desc_word_entropy  desc_avg_word_repetition  \\\n",
              "0           4.407766           4.084184                  1.111111   \n",
              "1           4.234203           4.321928                  1.000000   \n",
              "\n",
              "   desc_compression_ratio  desc_starts_with_emoji  desc_ends_with_emoji  \\\n",
              "0                0.889764                   False                 False   \n",
              "1                0.789809                   False                 False   \n",
              "\n",
              "   desc_starts_with_url  desc_ends_with_url  desc_contains_pipe_or_bullet  \\\n",
              "0                 False               False                         False   \n",
              "1                 False               False                         False   \n",
              "\n",
              "   desc_contains_call_to_action  desc_contains_ai_phrase  \\\n",
              "0                          True                    False   \n",
              "1                         False                    False   \n",
              "\n",
              "   desc_function_word_ratio  desc_noun_ratio  desc_verb_ratio  \\\n",
              "0                      0.20             0.50              0.1   \n",
              "1                      0.15             0.45              0.2   \n",
              "\n",
              "   desc_pronoun_ratio  desc_adjective_ratio  desc_contains_repeated_chars  \\\n",
              "0                0.05                  0.15                         False   \n",
              "1                0.05                  0.15                         False   \n",
              "\n",
              "  desc_is_retweet desc_is_quote  \n",
              "0            None          None  \n",
              "1            None          None  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "desc_feature_df = user_features[\"description\"].apply(extract_text_features).apply(pd.Series)\n",
        "desc_feature_df.rename(columns={c: f\"desc_{c}\" for c in desc_feature_df.columns}, inplace=True)\n",
        "\n",
        "user_features_1 = pd.concat([user_features, desc_feature_df], axis=1)\n",
        "user_features_1.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding text: 100%|██████████| 98/98 [1:25:04<00:00, 52.09s/it]\n"
          ]
        }
      ],
      "source": [
        "user_features_1[\"description_normalized\"] = user_features_1[\"description\"].apply(normalize_text)\n",
        "\n",
        "embedder = SentenceEmbedder()\n",
        "user_features_1[\"desc_embedding\"] = embedder.transform(user_features_1[\"description_normalized\"])[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../../02_data/user_features_1.joblib']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(user_features_1, f\"../../02_data/user_features_1.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_id</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>is_reply</th>\n",
              "      <th>is_sensitive</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1001495628738957312</td>\n",
              "      <td>t1502310945158275074</td>\n",
              "      <td>Join us for a special screening of the documentary #SAPELO and a Q&amp;amp;A with the filmmakers on Thursday, March 31 at the @CarterCenter!📽️🇨🇭 @CarterLibrary @SWISS_FILMS https://t.co/53nsRtRI8u</td>\n",
              "      <td>2022-03-11 15:50:15+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1002590470097154048</td>\n",
              "      <td>t1459274835377500161</td>\n",
              "      <td>Looking forward to meeting the final chapter👀👀 https://t.co/6NsqPBe272</td>\n",
              "      <td>2021-11-12 21:40:07+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>bot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              author_id                    id  \\\n",
              "0  u1001495628738957312  t1502310945158275074   \n",
              "1  u1002590470097154048  t1459274835377500161   \n",
              "\n",
              "                                                                                                                                                                                               text  \\\n",
              "0  Join us for a special screening of the documentary #SAPELO and a Q&amp;A with the filmmakers on Thursday, March 31 at the @CarterCenter!📽️🇨🇭 @CarterLibrary @SWISS_FILMS https://t.co/53nsRtRI8u   \n",
              "1                                                                                                                            Looking forward to meeting the final chapter👀👀 https://t.co/6NsqPBe272   \n",
              "\n",
              "                  created_at  in_reply_to_user_id  is_reply  is_sensitive  \\\n",
              "0  2022-03-11 15:50:15+00:00                  NaN         0             0   \n",
              "1  2021-11-12 21:40:07+00:00                  NaN         0             0   \n",
              "\n",
              "   like_count  quote_count  reply_count  retweet_count  label  \n",
              "0           1          0.0          0.0              1  human  \n",
              "1           0          NaN          NaN              0    bot  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweet_features = pd.read_parquet(f\"../../02_data/tweet_features_v1.parquet\", engine='pyarrow')\n",
        "tweet_features.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset contains 1048873 rows and 12 columns.\n"
          ]
        }
      ],
      "source": [
        "n_rows, n_columns = tweet_features.shape\n",
        "print(f\"The dataset contains {n_rows} rows and {n_columns} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweet_features['label'] = tweet_features['label'].map({'human': 0, 'bot': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tweet_feature_df = \u001b[43mtweet_features\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_tweet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.apply(pd.Series)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#tweet_feature_df.rename(columns={c: f\"tweet_{c}\" for c in tweet_feature_df.columns}, inplace=True)\u001b[39;00m\n\u001b[32m      4\u001b[39m tweet_features_1 = pd.concat([tweet_features, tweet_feature_df], axis=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\pandas\\core\\series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Studies\\Materials\\Second-cycle\\II year\\II trimester\\Thesis\\thesis\\thesis-venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tweet_feature_df = tweet_features[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mextract_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_tweet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m).apply(pd.Series)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#tweet_feature_df.rename(columns={c: f\"tweet_{c}\" for c in tweet_feature_df.columns}, inplace=True)\u001b[39;00m\n\u001b[32m      4\u001b[39m tweet_features_1 = pd.concat([tweet_features, tweet_feature_df], axis=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mextract_text_features\u001b[39m\u001b[34m(text, is_tweet)\u001b[39m\n\u001b[32m    169\u001b[39m word_entropy = entropy(\u001b[38;5;28mlist\u001b[39m(word_counts.values()), base=\u001b[32m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m word_counts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    170\u001b[39m avg_word_repetition = np.mean(\u001b[38;5;28mlist\u001b[39m(word_counts.values())) \u001b[38;5;28;01mif\u001b[39;00m word_counts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m compression_ratio = \u001b[38;5;28mlen\u001b[39m(zlib.compress(text.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))) / char_len\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# --- H: Template indicators\u001b[39;00m\n\u001b[32m    174\u001b[39m starts_with_emoji = text[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m emoji.EMOJI_DATA\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "tweet_feature_df = tweet_features[\"text\"].apply(lambda x: extract_text_features(x, is_tweet=True)).apply(pd.Series)\n",
        "#tweet_feature_df.rename(columns={c: f\"tweet_{c}\" for c in tweet_feature_df.columns}, inplace=True)\n",
        "\n",
        "tweet_features_1 = pd.concat([tweet_features, tweet_feature_df], axis=1)\n",
        "tweet_features_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweet_features_1[\"text_normalized\"] = tweet_features_1[\"text\"].apply(normalize_text)\n",
        "\n",
        "embedder = SentenceEmbedder()\n",
        "tweet_features_1[\"embedding\"] = embedder.transform(tweet_features_1[\"text_normalized\"])[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../../02_data/tweet_features_1.joblib']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(tweet_features_1, f\"../../02_data/tweet_features_1.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK-fRkI_7ftc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNKZgXrZg3RNJ0veUK2cafg",
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "thesis-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
